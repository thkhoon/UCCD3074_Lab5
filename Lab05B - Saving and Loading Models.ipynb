{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KD4xqavfrauc"
   },
   "source": [
    "# Lab5B - Saving and Loading Models\n",
    "\n",
    "In the process of training the model, you may stop the training temporarily and resume it later. You may also want to save the best model which may not be the model generated in the last iteration. More importantly, after completion of training, you want to deploy your model to the field. All this requires you to save and load the model.\n",
    "\n",
    "#### Objectives:\n",
    "In this practical, students learn how to:\n",
    "1. Save and loading models \n",
    "2. Resume previous training\n",
    "\n",
    "#### References:\n",
    "1. [Saving and loading models](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-MaOimXraup"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trq1_JvSraus"
   },
   "outputs": [],
   "source": [
    "cd \"./gdrive/MyDrive/UCCD3074_Labs/UCCD3074_Lab5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maayG5Hqraut"
   },
   "source": [
    "Import the required library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4eIiVvDraut",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "from cifar10 import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ug_zVaSQrauu"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./models\"):\n",
    "    os.mkdir(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWc-5XFjrauu"
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "When it comes to saving and loading models, there are three core functions to be familiar with:\n",
    "\n",
    "1. **`torch.save`**\n",
    "<br> Saves a serialized object to disk. This function uses Python’s pickle utility for serialization. Models, tensors, and dictionaries of all kinds of objects can be saved using this function.\n",
    "2. **`torch.load`** \n",
    "<br> Uses pickle’s unpickling facilities to deserialize pickled object files to memory. This function also facilitates the device to load the data into (see Saving & Loading Model Across Devices).\n",
    "3. **`torch.nn.Module.load_state_dict`**\n",
    "<br> Loads a model’s parameter dictionary using a deserialized state_dict. \n",
    "\n",
    "#### What is a `state_dict()`?\n",
    "\n",
    "* Each <u>model</u> has a `state_dict`. The model state_dict is simply a Python dictionary object that maps each layer to its parameter tensors stored in `model.parameters()`. `state_dict` stores the following tensors:\n",
    "  * learnable parameters (convolutional layers, linear layers, etc.)\n",
    "  * registered buffers (batchnorm's running mean).\n",
    "\n",
    "* The <u>optimizer object</u> (`torch.optim`) also have a `state_dict`, which contains information about \n",
    "  * the optimizer's state\n",
    "  * the hyperparameters used.\n",
    "\n",
    "Because `state_dict` objects are Python dictionaries, they can be easily saved, updated, altered, and restored, adding a great deal of modularity to PyTorch models and optimizers.\n",
    "\n",
    "First, let's build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6iLQuSPrauv"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1)   \n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)  \n",
    "        self.bn2   = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*30*30, 256) \n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # flat\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLxQAHx8rauw"
   },
   "source": [
    "The following shows the `state_dict` of the model. Note that `state_dict` stores not only the *parameters* (weight and bias) of the trainable layers but also the *running mean* of the batch norm layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv43ntb9rauw"
   },
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNc8mcutraux",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPxcZfRdraux"
   },
   "source": [
    "The following code shows the `state_dict` of the optimizer. It stores the *hyperparameter* settings (e.g., `lr`, `momentum`, `dampening`, `weight_decay`, `nesterov`) as well as the *optimizer* states (`params`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwrBtXvZrauy"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzVeJCjyrauy"
   },
   "outputs": [],
   "source": [
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkCH6Tpvrauy"
   },
   "source": [
    "---\n",
    "\n",
    "## 1.1 Saving & Loading Model Parameters Only\n",
    "\n",
    "**`torch.save(model.state_dict(), PATH)`**\n",
    "\n",
    "When saving a model for inference, it is only necessary to save the trained model’s learned parameters. We do not need to save the network structure itself. To do that, use the command `torch.save()`. A common PyTorch convention is to save models using either a `.pt` or `.pth` file extension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSmnPirSrauz"
   },
   "outputs": [],
   "source": [
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_XNubYLrau0"
   },
   "source": [
    "model.**`load_state_dict(torch.load(PATH))`**\n",
    "\n",
    "To load the model parameters, use the model's function `load_state_dict()`. `load_state_dict()` takes a dictionary object, NOT a path to a saved object. So, you must deserialize the saved state_dict first (`torch.load(PATH)`) before you pass it to the `load_state_dict()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-R4u8CkWrau1"
   },
   "outputs": [],
   "source": [
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SExwT3e5rau2"
   },
   "source": [
    "---\n",
    "## 1.2 Saving the Entire Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKMWoxb9rau2"
   },
   "source": [
    "The previous method only saves the model *parameters* but not the *network* itself. As a result, the saved parameters must be accompanied by the *model class*, i.e., the class `Net`, so that we can create the *network* first before loading the parameters. Because of this, your code can break in various ways when used in other projects or after refactors.\n",
    "\n",
    "\n",
    "**`torch.save(model, PATH)`**\n",
    "\n",
    "You may save the whole model and use it for inference by providing `model` rather than `model.state_dict()` as the argument for `torch.save`. This eliminates the need to attach the model class together with your saved model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3-S5AGMrau3"
   },
   "outputs": [],
   "source": [
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvTzpU2Wrau6"
   },
   "source": [
    "**model = `torch.load(PATH)`**\n",
    "\n",
    "When we load, we load both the network and the model. There is no need for us to create the model first: `new_model2 = Net()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZL9aO1Lrau7"
   },
   "outputs": [],
   "source": [
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_X-bkWJrau7"
   },
   "source": [
    "**Caution**: \n",
    "\n",
    "* If you are doing inference, remember that you must call `model.eval()` to set *dropout* and *batch normalization* layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results. \n",
    "\n",
    "* If you wish to resuming training, call `model.train()` to ensure these layers are in training mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQA_YAxnrau7"
   },
   "source": [
    "---\n",
    "## 1.3 Saving the Model Parameters and Optimizer State\n",
    "\n",
    "It is common to train your model in multiple session where you stop the training temporarily and resume it only at a later day. To do this you need to save **checkpoints**. \n",
    "\n",
    "When saving a checkpoint, to be used for either inference or resuming training, you must save more than just the model’s state_dict. It is important to also save:\n",
    "1. optimizer's state_dict \n",
    "2. model's state_dict \n",
    "3. current epoch number\n",
    "4. training loss\n",
    "5. others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3KbQOQ2rau8"
   },
   "source": [
    "Assume the following as the current state of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWu1cSRIrau8"
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "loss = np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_C3J4jW_rau8"
   },
   "source": [
    "To save multiple components, you can organize them into a dictionary and use `torch.save()` to serialize the dictionary. A common PyTorch convention is to save these checkpoints using the `.tar` file extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owORZaTArau9"
   },
   "outputs": [],
   "source": [
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKWXdb-nrau9"
   },
   "outputs": [],
   "source": [
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53WiqTVPrau9"
   },
   "source": [
    "First, load the *network's parameters* and *optimizer's state*. For the *optimizer*, the learning rate (`lr`) is a compulsory argument. It will be overwritten when we load the saved optimizer's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWEAWCaCrau-"
   },
   "outputs": [],
   "source": [
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43h6HUU4rau-"
   },
   "source": [
    "Since you wish to resuming training, remember to call `model.train()` to ensure that that the dropout and batch normalization layers are in training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9RKbLxorau-"
   },
   "outputs": [],
   "source": [
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tMxRbzLrau-"
   },
   "source": [
    "Now you are ready to resume your training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXdTx3vVrau_"
   },
   "source": [
    "---\n",
    "# 2. Example\n",
    "\n",
    "## Load the dataset\n",
    "We will use the CIFAR10 dataset for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zz0NRUDrau_"
   },
   "outputs": [],
   "source": [
    "# transform the model\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# dataset\n",
    "trainset = CIFAR10(train=True,  transform=transform, num_samples=10000)\n",
    "validset  = CIFAR10(train=False,  transform=transform, num_samples=2000)\n",
    "\n",
    "# dataloader]\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "validloader  = DataLoader(validset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7cxZOqGravA"
   },
   "source": [
    "## Define training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HoPliigravA"
   },
   "source": [
    "First, we define our training model. To allow the model to resume training, we do the following:\n",
    "1. Define the `model` and `optimizer` outside the `train` function\n",
    "2. Save the model at the end of each epoch (`line 56` to `62`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWYzXabVravA"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rS_OWpUgravA"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, start_epoch=0, max_epochs=10):\n",
    "    \n",
    "    # compute loss 3 times in each epoch\n",
    "    loss_iterations = int(np.ceil(len(trainloader)/3))\n",
    "    \n",
    "    # transfer model to GPU\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # set the optimizer. Use SGD with momentum\n",
    "    \n",
    "    # set to training mode\n",
    "    model.train()\n",
    "        \n",
    "    # train the network\n",
    "    #... your code here ... \n",
    "\n",
    "        running_loss = 0\n",
    "        running_count = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "            # Clear all the gradient to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # transfer data to GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward propagation to get h\n",
    "            outs = model(inputs)\n",
    "\n",
    "            # compute loss \n",
    "            loss = F.cross_entropy(outs, labels)\n",
    "\n",
    "            # backpropagation to get gradients of all parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # get the loss\n",
    "            running_loss += loss.item()\n",
    "            running_count += 1\n",
    "\n",
    "             # display the averaged loss value \n",
    "            if i % loss_iterations == loss_iterations-1 or i == len(trainloader) - 1:    \n",
    "                # compute training loss\n",
    "                train_loss = running_loss / running_count\n",
    "                running_loss = 0. \n",
    "                running_count = 0.\n",
    "               \n",
    "                print(f'[Epoch {e+1:2d} Iter {i+1:5d}/{len(trainloader)}]: train_loss = {train_loss:.4f}')       \n",
    "            \n",
    "        \n",
    "        # save the model \n",
    "        ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntLfRoz3ravB"
   },
   "source": [
    "## Train model \n",
    "\n",
    "Train the model for 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLjyY06cravB"
   },
   "outputs": [],
   "source": [
    "lr=0.01; momentum=0.9\n",
    "\n",
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "train(model, optimizer, max_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gbv2tMJRravB"
   },
   "source": [
    "## Resume training\n",
    "\n",
    "Resume training and train for another 2 epochs. To do that, we get the load the *previous* model's and optimizer's `state_dict`, the last epoch and training loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SK-iWCf2ravC"
   },
   "outputs": [],
   "source": [
    "# define a new model\n",
    "#... your code here ...\n",
    "\n",
    "# define a new optimizer\n",
    "#... your code here ...\n",
    "\n",
    "# load the checkpoint file\n",
    "#... your code here ...\n",
    "\n",
    "# resume training\n",
    "print(f'Resuming previous epoch. Last run epoch: {previous_epoch+1}, last run loss: {previous_loss:.4f}')\n",
    "#... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTBgpPzjravC"
   },
   "source": [
    "<center> --- END OF LAB --- </center>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab05C - Saving and Loading Models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
