{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t42KE94qArc"
   },
   "source": [
    "# Lab5A - Constructing a CNN Network\n",
    "\n",
    "For spatial data for example image or video data, Convolutional Neural Network (CNN or ConvNet) performs much better than  standard neural network. In this practical, we shall learn how to build a CNN Network.\n",
    "\n",
    "#### Objectives:\n",
    "1. Learn how to build a convolutional neural network (CNN)\n",
    "2. Learn how to build a network or layer using `sequential` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO8SoeLkukMh"
   },
   "source": [
    "Remember to **enable the GPU** (Edit > Notebook setting > GPU) to ensure short training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2kRNHKJqArg"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R26k7bWMqArm"
   },
   "outputs": [],
   "source": [
    "cd \"/content/gdrive/MyDrive/UCCD3074_Labs/UCCD3074_Lab5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpacRGR5qArs"
   },
   "source": [
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gtf8CwDdqArt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from cifar10 import CIFAR10\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsxY9aORqAsO"
   },
   "source": [
    "---\n",
    "\n",
    "# SECTION 1. DEFINING A CNN MODULE WITH `torch.nn.Module`\n",
    "\n",
    "In this section, we create a CNN network using `nn.Module`. The `Module` is the main building block, it defines the base class for all neural network and you MUST subclass it. \n",
    "\n",
    "## 1.1 Build the network\n",
    "\n",
    "**Exercise**. Build the following CNN. You will need to following modules:\n",
    "* To define a conv2d layer: [`torch.nn.Conv2d(in_channel, out_channel, kernel_size, stride=1, padding=0)`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "   * `in_channel`: number of channels in the input tensor. \n",
    "   * `out_channel`: number of channels in the output tensor. This is equivalent to the number of filters in the current convolutional layer.\n",
    "   * `kernel_size`: size of the filter (`f`).\n",
    "   * `stride`: stride (`s`). Default value is 1.\n",
    "   * `padding`: padding (`p`). Default value is 0.\n",
    "\n",
    "* To define a max pooling layer: [`torch.nn.functional.max_pool2d (x, kernel_size, stride=None, padding=0)`](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html#torch.nn.functional.max_pool2d)\n",
    "   * `x`: input tensor of shape `(b, c, h, w)`. This is required as this is a `functional` operation.\n",
    "   * `kernel_size`: size of the filter (`f`).\n",
    "   * `stride`: stride (`s`). Default value is `kernel_size`.\n",
    "   * `padding`: padding (`p`). Default value is 0.\n",
    "\n",
    "* To define a linear layer: [`torch.nn.Linear (in_features, out_features)`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "  * `in_features`:  size of each input sample. This is equivalent to the number of units or signals in the previous layer.\n",
    "  * `out_features`: size of the output sample. This is equivalent to the number of units / neurons in the current layer.\n",
    "\n",
    "* To define the global average pooling: [`torch.mean (x, dim)`](https://pytorch.org/docs/stable/generated/torch.mean.html)\n",
    "    * `x`: the input tensor\n",
    "    * `dim`: the dimensions to reduce. For the input tensor is `(b, c, h, w)`, to compute the mean of the spatial dimensions `h` and `w`, set `dim = [2, 3]`. This will compute the mean for the spatial dimensions and output a tensor of shape `(b, c, 1, 1)`. Then, use [`torch.squeeze`](https://pytorch.org/docs/stable/generated/torch.squeeze.html#torch.squeeze) to remove the two empty dimensions to get a tensor of shape `(b, c)`.\n",
    "\n",
    "* Alternatively, the global average pooling can be defined using the following command: [`torch.nn.AdaptiveAvgPool2d (output_size)`](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html)\n",
    "    * `output size`: the target output size (`o`). The layer will configure the kernel size as `(input_size+target_size-1)//target_size` to generate an output tensor of shape `output_size`. \n",
    "\n",
    "<br><center><b>Network Architecture </b></center>\n",
    "\n",
    "|Layer | Name | Description | OutputShape |\n",
    "|:--:|:--|:---:|---|\n",
    "| - | Input       | -                            | (?,  3, 32, 32) |\n",
    "| 1 | conv1       | Conv2d (k=32, f=3, s=1, p=1) | (?, 32, 32, 32) |\n",
    "|   |             | relu                         | (?, 32, 32, 32) | \n",
    "| 2 | conv2       | Conv2d (k=32, f=3, s=1, p=1) | (?, 32, 32, 32) | \n",
    "|   |             | relu                         | (?, 32, 32, 32) |\n",
    "|   | pool1       | maxpool (f=2, s =2, p=0)     | (?, 32, 16, 16) |\n",
    "| 3 | conv3       | Conv2d (k=64, f=3, s=1, p=1) | (?, 64, 16, 16) | \n",
    "|   |             | relu                         | (?, 64, 16, 16) |  \n",
    "| 4 | conv4       | Conv2d (k=64, f=3, s=1, p=1) | (?, 64, 16, 16) | \n",
    "|   |             | relu                         | (?, 64, 16, 16) |  \n",
    "|   | global_pool | AdaptiveAvgPool (o=(1,1))    | (?, 64, 1, 1)   | \n",
    "|   |             | view                         | (?, 64)         | \n",
    "| 5 | fc1         | Linear (#units=10)           | (?, 10)         | \n",
    "\n",
    "Notes: `k`: number of filters, `f`: filter or kernel size, `s`: stride, `p`: padding, `o`: output shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWtkUN98qArz"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaxRAiLMqAsP"
   },
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        # call super constructor\n",
    "        # ... your code here ...\n",
    "\n",
    "        # create the conv1 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # create the conv2 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # create the conv3 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # create the conv4 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # create the global pooling layer\n",
    "        # ... your code here ...\n",
    "\n",
    "        # fully connected layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # conv1 layer\n",
    "        # ... your code here ...\n",
    "        pass\n",
    "\n",
    "        # conv2 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # pooling layer\n",
    "        # ... your code here ...\n",
    "\n",
    "        # conv3 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # conv4 layer\n",
    "        # ... your code here ...\n",
    "\n",
    "        # global pooling\n",
    "        # ... your code here ...\n",
    "\n",
    "        # remove the spatial dimension\n",
    "        # ... your code here ...\n",
    "\n",
    "        # fc1 layer\n",
    "        # ... your code here ...\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OMTsYGJi9mz"
   },
   "source": [
    "Create the network and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RUhB0J1kC-E"
   },
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfbIVb5CUvkR"
   },
   "source": [
    "Display the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BLNQcxaqAsg"
   },
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9omfHlxWqAsj"
   },
   "source": [
    "## 1.2 Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4a9BnP1wtvi"
   },
   "source": [
    "1. Load the dataset. Define the following transformation pipeline to \n",
    "* Convert an image (numpy array with range (0, 255)) to a tensor, and \n",
    "*  Normalize the tensor with mean = 0.5 and std = 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0zbSP3sb681"
   },
   "outputs": [],
   "source": [
    "# transform the model\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1., 1., 1.))\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "trainset = CIFAR10(train=True,  transform=transform, download=True, num_samples=10000)\n",
    "testset  = CIFAR10(train=False,  transform=transform, download=True, num_samples=2000)\n",
    "\n",
    "print('Size of trainset:', len(trainset))\n",
    "print('Size of testset:', len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2L1gHLjfxXcS"
   },
   "source": [
    "2. Create the dataloader for train set and test set. Use a batch size of 16, enable shuffle, apply the transformation pipeline defined above and use 2 cpu workers to load the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8idPx0HxxTZB"
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
    "testloader  = DataLoader(testset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AyYjyqCyBiE"
   },
   "source": [
    "## 1.3 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkwr-hcnyNuj"
   },
   "outputs": [],
   "source": [
    "def train(net, trainloader, num_epochs, lr=0.1, momentum=0.9):\n",
    "    \n",
    "    loss_iterations = int(np.ceil(len(trainloader)/3))\n",
    "    \n",
    "    # transfer model to GPU\n",
    "    net = net.to(device)\n",
    "    \n",
    "    # set the optimizer. Use the SGD optimizer. Use the lr and momentum settings passed by the user\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    # set to training mode\n",
    "    net.train()\n",
    "\n",
    "    # variables\n",
    "    best_loss = np.inf\n",
    "    saturate_count = 0\n",
    "    \n",
    "    # train the network\n",
    "    for e in range(num_epochs):    \n",
    "\n",
    "        running_loss = 0\n",
    "        running_count = 0\n",
    "\n",
    "        # for all batch samples\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "            # Clear all the gradient to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # transfer data to GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward propagation to get h\n",
    "            outs = net(inputs)\n",
    "\n",
    "            # compute loss \n",
    "            loss = F.cross_entropy(outs, labels)\n",
    "\n",
    "            # backpropagation to get gradients of all parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # get the loss\n",
    "            running_loss += loss.item()\n",
    "            running_count += 1\n",
    "\n",
    "             # display the averaged loss value \n",
    "            if i % loss_iterations == loss_iterations-1 or i == len(trainloader) - 1:                \n",
    "                train_loss = running_loss / running_count\n",
    "                running_loss = 0. \n",
    "                running_count = 0.\n",
    "                print(f'[Epoch {e+1:2d} Iter {i+1:5d}/{len(trainloader)}]: train_loss = {train_loss:.4f}')       \n",
    "                \n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Fh5B5cqypGQ"
   },
   "source": [
    "Now, train the model for 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hh5lypvVqAsk"
   },
   "outputs": [],
   "source": [
    "train(net, trainloader, num_epochs=15, lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJQVHE3tqAsr"
   },
   "source": [
    "## 3. Evaluate the model\n",
    "\n",
    "Now let's evaluate the model. Remember that a 2-layered neural network only achieves an accuracy of around 38%. With a CNN architecture, you should be able to achieve a higher accuracy of more than 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbuUhbily-Mw"
   },
   "outputs": [],
   "source": [
    "def evaluate(net, testloader):\n",
    "    \n",
    "    # set to evaluation mode\n",
    "    net.eval() \n",
    "\n",
    "    # running_correct\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Repeat for all batch data in the test set\n",
    "    for inputs, targets in testloader:\n",
    "\n",
    "        # transfer to the GPU\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # # disable gradient computation\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # perform inference\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # predict as the best result  \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            running_corrects += (targets == predicted).double().sum()\n",
    "\n",
    "\n",
    "    print('Accuracy = {:.2f}%'.format(100*running_corrects/len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVmtZB_fy-8C"
   },
   "source": [
    "Now, let's evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Q0woXISqAst"
   },
   "outputs": [],
   "source": [
    "evaluate(net, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-oxEglpqAsx"
   },
   "source": [
    "---\n",
    "# 2. CREATING A CNN NETWORK DIRECTLY USING torch.nn.Sequential\n",
    "\n",
    "In this section, we shall learn how to create a network using `torch.nn.Sequential`. `Sequential` is a container of `Modules` that can be stacked together and run at the same time. \n",
    "\n",
    "```\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(....),\n",
    "    nn.ReLU(),\n",
    "    ....\n",
    ")\n",
    "\n",
    "x = ... # get the input tensor\n",
    "output = net(x)  # perform inference\n",
    "```\n",
    "\n",
    "We can see immediately that it is a very convenient way to build a network.\n",
    "\n",
    "*Limitations: Note that you cannot add functional operations (e.g., `torch.relu`) into a `Sequential` model. If the `nn` module version does not exist for the function, then you have to create your own `nn` module for the function.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hntw80gqAs4"
   },
   "source": [
    "**Exercise**. Reimplement the network above using `torch.nn.Sequential`. \n",
    "\n",
    "Since you cannot use functional operations for `Sequential` models, you use their corresponding module versions:\n",
    "* `torch.nn.functional.max_pool2d` --> [`torch.nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)\n",
    "* `torch.nn.functional.relu` --> [`torch.nn.ReLU`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)\n",
    "* `torch.view` --> [`nn.Flatten`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjYESW_IqAs7"
   },
   "outputs": [],
   "source": [
    "net2 = # ... your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDp67m2XJC_m"
   },
   "outputs": [],
   "source": [
    "summary(net2, input_size=(4, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PB-IrMHsqAtC"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kl5_NdRPqAtD"
   },
   "outputs": [],
   "source": [
    "train(net2, trainloader, num_epochs=15, lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlYw_V9SqAtH"
   },
   "source": [
    "### Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJWpnTqnqAtI"
   },
   "outputs": [],
   "source": [
    "evaluate(net2, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV7MzAewqAtO"
   },
   "source": [
    "---\n",
    "# 3. Using a function to create a customizable BLOCK module\n",
    "\n",
    "In the following, we group the convolutional layers in the network above into 2 blocks:\n",
    "* `conv1` and `conv2` --> `block_1`\n",
    "* `conv3` and `conv4` --> `block_2`.\n",
    "\n",
    "This is how the network looks:\n",
    "\n",
    "<center> <b> NETWORK (with block) </b> </center>\n",
    "\n",
    "| Block |Layer | Name | Description | OutputShape |\n",
    "|:---:|:--:|:--|:---:|:---:|\n",
    "|input|-|-|-|(?, 3, 32, 32)|\n",
    "||||||\n",
    "| block_1 <br> (blk_cin=3, blk_cout=32) | 1 <br><br> - <br><br> 2 <br><br> - | conv1 <br><br> ReLU <br><br> conv2 <br><br> ReLU| Conv2d (in_channels=3, out_channels=32,f=3,s=1,p=1)<br><br> relu <br><br> Conv2d (in_channels=32, out_channels=32,f=3,s=1,p=1)<br><br> relu| (?, 32, 32, 32) <br><br> (?, 32, 32, 32)<br><br> (?, 32, 32, 32)<br><br> (?, 32, 32, 32) | \n",
    "||||||\n",
    "| - | - | pool1 | maxpool (f=2,s=2,p=0) | (?, 32, 16, 16) | \n",
    "||||||\n",
    "| block_2 <br> (blk_cin=32, blk_cout=64) | 3 <br><br> - <br><br> 4 <br><br> - | conv1 <br><br> ReLU <br><br> conv2 <br><br> ReLU| Conv2d (in_channels=32, out_channels=64,f=3,s=1,p=1)<br><br> relu <br><br> Conv2d (in_channels=64, out_channels=64, f=3,s=1,p=1)<br><br> relu| (?, 64, 16, 16) <br><br> (?, 64, 16, 16)<br><br> (?, 64, 16, 16)<br><br> (?, 64, 16, 16) | \n",
    "||||||\n",
    "|  | - | global_pool | AdaptiveAvgPool, o=(1,1) | (?, 64, 1, 1) | \n",
    "|  | - | -           | view                     | (?, 64) | \n",
    "||||||\n",
    "|  | 5 | fc1         | Linear(#units=10)        | (?, 10) | \n",
    "|  | - | -           | view                     | (?, 10) | \n",
    "\n",
    "<br>\n",
    "<center> Notes: <i>k</i>: number of filters, <i>f</i>: filter or kernel size, <i>s</i>: stride, <i>p</i>: padding, <i>o</i>: output shape </center>\n",
    "\n",
    "\n",
    "Comparing `block_1` and `block_2`, we find that they have similar structure\n",
    "\n",
    "`conv (blk_cin, blk_cout)  --> relu --> conv (blk_cout, blk_cout) --> relu` \n",
    "\n",
    "where \n",
    "\n",
    "* `blk_cin=3` and `blk_cout=32` for `block1`\n",
    "* `blk_cin=32` and `blk_cout=64` for `block2`\n",
    "\n",
    "This means that we can use the same function to create `block1` and `block2`. we shall do precisely this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvMnqNBbng44"
   },
   "source": [
    "### The BUILD_BLOCK function\n",
    "\n",
    "Rather than declaring each layer individually, you create a function `build_block` to create a block of layers. The function receives `in_ch`, the number of channels in the input tensor and `out_ch`, the number of channels in the output tensor.  In the following, complete the `build_block` function by returning a `nn.Sequential` module that builds and returns the following block\n",
    "\n",
    "| BLOCK (blk_cin, blk_cout) |\n",
    "|:--:|\n",
    "| Conv2d (in_channels=blk_cin, output_channels=blk_cout, f=3, s=1,p=1) |\n",
    "| ReLU () |\n",
    "| Conv2d (in_channels=blk_cout, output_channels=blk_cout, f=3, s=1,p=1) |\n",
    "| ReLU () |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XgXW69YqAtO"
   },
   "outputs": [],
   "source": [
    "def build_block(blk_cin, blk_cout):\n",
    "    block = # ... use nn.Sequential to create the block ...\n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OszgHvgPnyeV"
   },
   "source": [
    "### Constructing the network with BUILD_BLOCK\n",
    "\n",
    "Now, construct `NETWORK (with block)`. Use the `build_block` function to construct `block1` and `block2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEp2curgn2c-"
   },
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ... define block 1 ...\n",
    "        \n",
    "        # ... define block 2 ...\n",
    "\n",
    "        # define global_pool\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        \n",
    "        # define fc1\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # ... forward prop through block 1 ...\n",
    "        \n",
    "        # max pool\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # block 2\n",
    "        # ... forward prop through block 1 ...\n",
    "        \n",
    "        # global pool\n",
    "        x = self.global_pool(x)\n",
    "\n",
    "        # view\n",
    "        x = x.view(x.size(0), -1) \n",
    "        \n",
    "        # fc1\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oveXjq-goD51"
   },
   "outputs": [],
   "source": [
    "net3 = Net3()\n",
    "summary(net3, input_size=(4, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmSeYyMNoGM4"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQ9UnZS8oHLb"
   },
   "outputs": [],
   "source": [
    "train(net3, trainloader, num_epochs=15, lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCgz35FyoJVO"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mD9ZF4qwoJpN"
   },
   "outputs": [],
   "source": [
    "evaluate(net3, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zit73MLhoMnN"
   },
   "source": [
    "---\n",
    "# 4. Create a customizable BLOCK module\n",
    "\n",
    "We can also build a block by constructing a module called `BLOCK` where we can specify the `blk_cin` and `blk_cin` when constructing the block.\n",
    "\n",
    "\n",
    "### The BLOCK module\n",
    "\n",
    "Implement the BLOCK module.\n",
    "\n",
    "| BLOCK (blk_cin, blk_cout) |\n",
    "|:--:|\n",
    "| Conv2d (in_channels=blk_cin, output_channels=blk_cout, f=3, s=1,p=1) |\n",
    "| ReLU () |\n",
    "| Conv2d (in_channels=blk_cout, output_channels=blk_cout, f=3, s=1,p=1) |\n",
    "| ReLU () |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEWFj-WHoZIU"
   },
   "outputs": [],
   "source": [
    "class BLOCK(nn.Module):\n",
    "\n",
    "    # ... define the init layer ...\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        # ... define the convolutional layers ... \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # ...  forward propagation ... \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "De2YPbrfoZZ8"
   },
   "source": [
    "### Construcing network with the BLOCK module\n",
    "\n",
    "Now, let's build the network using the `BLOCK` module that we have just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WpAyUwgoZiw"
   },
   "outputs": [],
   "source": [
    "class Net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ... define block 1 ...\n",
    "        \n",
    "        # ... define block 2 ...\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))        \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # ... block 1 ...\n",
    "        \n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # ... block 2 ...\n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOrPY7W_oZqq"
   },
   "outputs": [],
   "source": [
    "net4 = Net4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1p3KmfWo5Xp"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pApBfh_Ho5fT"
   },
   "outputs": [],
   "source": [
    "train(net4, trainloader, num_epochs=15, lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKyz_F1Ho5qE"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWldd5MKo51c"
   },
   "outputs": [],
   "source": [
    "evaluate(net4, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df2XKfZlSM8R"
   },
   "source": [
    "<center>--- End of Practical ---</center>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab05A - Constructing a CNN Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
