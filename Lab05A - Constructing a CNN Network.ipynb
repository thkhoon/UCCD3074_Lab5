{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t42KE94qArc"
   },
   "source": [
    "# Lab5A - Constructing a CNN Network\n",
    "\n",
    "For spatial data for example image or video data, Convolutional Neural Network (CNN or ConvNet) performs much better than  standard neural network. In this practical, we shall learn how to build a CNN Network.\n",
    "\n",
    "#### Objectives:\n",
    "1. Learn how to build a convolutional neural network (CNN)\n",
    "2. Learn how to build a network or layer using `sequential` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO8SoeLkukMh"
   },
   "source": [
    "Remember to **enable the GPU** (Edit > Notebook setting > GPU) to ensure short training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2kRNHKJqArg"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R26k7bWMqArm"
   },
   "outputs": [],
   "source": [
    "cd \"/content/gdrive/MyDrive/UCCD3074_Labs/UCCD3074_Lab5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpacRGR5qArs"
   },
   "source": [
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gtf8CwDdqArt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from cifar10 import CIFAR10\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsxY9aORqAsO"
   },
   "source": [
    "---\n",
    "\n",
    "# SECTION 1. DEFINING A CNN MODULE WITH `torch.nn.Module`\n",
    "\n",
    "In this section, we create a CNN network using `nn.Module`. The `Module` is the main building block, it defines the base class for all neural network and you MUST subclass it. \n",
    "\n",
    "## 1.1 Build the network\n",
    "\n",
    "**Exercise**. Build the following CNN. You will need to following modules:\n",
    "* To define a conv2d layer: [`torch.nn.Conv2d(in_channel, out_channel, kernel_size, stride=1, padding=0)`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "   * `in_channel`: number of channels in the input tensor. \n",
    "   * `out_channel`: number of channels in the output tensor. This is equivalent to the number of filters in the current convolutional layer.\n",
    "   * `kernel_size`: size of the filter (`f`).\n",
    "   * `stride`: stride (`s`). Default value is 1.\n",
    "   * `padding`: padding (`p`). Default value is 0.\n",
    "\n",
    "* To define a max pooling layer: [`torch.nn.functional.max_pool2d (x, kernel_size, stride=None, padding=0)`](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html#torch.nn.functional.max_pool2d)\n",
    "   * `x`: input tensor of shape `(b, c, h, w)`. This is required as this is a `functional` operation.\n",
    "   * `kernel_size`: size of the filter (`f`).\n",
    "   * `stride`: stride (`s`). Default value is `kernel_size`.\n",
    "   * `padding`: padding (`p`). Default value is 0.\n",
    "\n",
    "* To define a linear layer: [`torch.nn.Linear (in_features, out_features)`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "  * `in_features`:  size of each input sample. This is equivalent to the number of units or signals in the previous layer.\n",
    "  * `out_features`: size of the output sample. This is equivalent to the number of units / neurons in the current layer.\n",
    "\n",
    "* To define the global average pooling: [`torch.mean (x, dim)`](https://pytorch.org/docs/stable/generated/torch.mean.html)\n",
    "    * `x`: the input tensor\n",
    "    * `dim`: the dimensions to reduce. For the input tensor is `(b, c, h, w)`, to compute the mean of the spatial dimensions `h` and `w`, set `dim = [2, 3]`. This will compute the mean for the spatial dimensions and output a tensor of shape `(b, c, 1, 1)`. Then, use [`torch.squeeze`](https://pytorch.org/docs/stable/generated/torch.squeeze.html#torch.squeeze) to remove the two empty dimensions to get a tensor of shape `(b, c)`.\n",
    "\n",
    "* Alternatively, the global average pooling can be defined using the following command: [`torch.nn.AdaptiveAvgPool2d (output_size)`](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html)\n",
    "    * `output size`: the target output size (`o`). The layer will configure the kernel size as `(input_size+target_size-1)//target_size` to generate an output tensor of shape `output_size`. \n",
    "\n",
    "<br><center><b>Network Architecture </b></center>\n",
    "\n",
    "|Layer | Name | Description | OutputShape |\n",
    "|:--:|:--|:---:|---|\n",
    "| - | Input       | -                            | (?,  3, 32, 32) |\n",
    "| 1 | conv1       | Conv2d (k=32, f=3, s=1, p=1) | (?, 32, 32, 32) |\n",
    "|   |             | relu                         | (?, 32, 32, 32) | \n",
    "| 2 | conv2       | Conv2d (k=32, f=3, s=1, p=1) | (?, 32, 32, 32) | \n",
    "|   |             | relu                         | (?, 32, 32, 32) |\n",
    "|   | pool1       | maxpool (f=2, s =2, p=0)     | (?, 32, 16, 16) |\n",
    "| 3 | conv3       | Conv2d (k=64, f=3, s=1, p=1) | (?, 64, 16, 16) | \n",
    "|   |             | relu                         | (?, 64, 16, 16) |  \n",
    "| 4 | conv4       | Conv2d (k=64, f=3, s=1, p=1) | (?, 64, 16, 16) | \n",
    "|   |             | relu                         | (?, 64, 16, 16) |  \n",
    "|   | global_pool | AdaptiveAvgPool (o=(1,1))    | (?, 64, 1, 1)   | \n",
    "|   |             | view                         | (?, 64)         | \n",
    "| 5 | fc1         | Linear (#units=10)           | (?, 10)         | \n",
    "\n",
    "Notes: `k`: number of filters, `f`: filter or kernel size, `s`: stride, `p`: padding, `o`: output shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWtkUN98qArz"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaxRAiLMqAsP"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # call super constructor\n",
    "        # ... your code here ...\n",
    "\n",
    "        # create the conv1 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # create the conv2 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # create the conv3 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # create the conv4 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # create the global pooling layer\n",
    "        # ... your code here ...\n",
    "\n",
    "        # fully connected layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # conv1 layer\n",
    "        # ... your code here ...\n",
    "        pass\n",
    "\n",
    "        # conv2 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # pooling layer\n",
    "        # ... your code here ...\n",
    "\n",
    "        # conv3 layer\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # conv4 layer\n",
    "        # ... your code here ...\n",
    "\n",
    "        # global pooling\n",
    "        # ... your code here ...\n",
    "\n",
    "        # remove the spatial dimension\n",
    "        # ... your code here ...\n",
    "\n",
    "        # fc1 layer\n",
    "        # ... your code here ...\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OMTsYGJi9mz"
   },
   "source": [
    "Create the network and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RUhB0J1kC-E"
   },
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfbIVb5CUvkR"
   },
   "source": [
    "Display the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BLNQcxaqAsg"
   },
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9omfHlxWqAsj"
   },
   "source": [
    "## 1.2 Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4a9BnP1wtvi"
   },
   "source": [
    "1. Load the dataset. Define the following transformation pipeline to \n",
    "* Convert an image (numpy array with range (0, 255)) to a tensor, and \n",
    "*  Normalize the tensor with mean = 0.5 and std = 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0zbSP3sb681"
   },
   "outputs": [],
   "source": [
    "# transform the model\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1., 1., 1.))\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "trainset = CIFAR10(train=True,  transform=transform, download=True, num_samples=10000)\n",
    "testset  = CIFAR10(train=False,  transform=transform, download=True, num_samples=2000)\n",
    "\n",
    "print('Size of trainset:', len(trainset))\n",
    "print('Size of testset:', len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2L1gHLjfxXcS"
   },
   "source": [
    "2. Create the dataloader for train set and test set. Use a batch size of 16, enable shuffle, apply the transformation pipeline defined above and use 2 cpu workers to load the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8idPx0HxxTZB"
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
    "testloader  = DataLoader(testset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AyYjyqCyBiE"
   },
   "source": [
    "## 1.3 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkwr-hcnyNuj"
   },
   "outputs": [],
   "source": [
    "def train(net, trainloader, max_epochs, lr=0.1, momentum=0.9):\n",
    "    \n",
    "    loss_iterations = int(np.ceil(len(trainloader)/3))\n",
    "    \n",
    "    # transfer model to GPU\n",
    "    net = net.to(device)\n",
    "    \n",
    "    # set the optimizer. Use the SGD optimizer. Use the lr and momentum settings passed by the user\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    # set to training mode\n",
    "    net.train()\n",
    "\n",
    "    # variables\n",
    "    best_loss = np.inf\n",
    "    saturate_count = 0\n",
    "    \n",
    "    # train the network\n",
    "    for e in range(max_epochs):    \n",
    "\n",
    "        running_loss = 0\n",
    "        running_count = 0\n",
    "\n",
    "        # for all batch samples\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "            # Clear all the gradient to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # transfer data to GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward propagation to get h\n",
    "            outs = net(inputs)\n",
    "\n",
    "            # compute loss \n",
    "            loss = F.cross_entropy(outs, labels)\n",
    "\n",
    "            # backpropagation to get gradients of all parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # get the loss\n",
    "            running_loss += loss.item()\n",
    "            running_count += 1\n",
    "\n",
    "             # display the averaged loss value \n",
    "            if i % loss_iterations == loss_iterations-1 or i == len(trainloader) - 1:                \n",
    "                train_loss = running_loss / running_count\n",
    "                running_loss = 0. \n",
    "                running_count = 0.\n",
    "                print(f'[Epoch {e+1:2d} Iter {i+1:5d}/{len(trainloader)}]: train_loss = {train_loss:.4f}')       \n",
    "                \n",
    "                if train_loss < best_loss:\n",
    "                    best_loss = train_loss\n",
    "                    saturate_count = 0\n",
    "                else:\n",
    "                    saturate_count += 1\n",
    "                    if saturate_count >= 3:\n",
    "                        return\n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Fh5B5cqypGQ"
   },
   "source": [
    "Now, train the model with a maximum number of epochs of 50. The training will stop once it converge and may stop earlier. Use a learning rate of 0.01 and momentum of 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hh5lypvVqAsk"
   },
   "outputs": [],
   "source": [
    "train(net, trainloader, max_epochs=50, lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJQVHE3tqAsr"
   },
   "source": [
    "## 3. Evaluate the model\n",
    "\n",
    "Now let's evaluate the model. Remember that a 2-layered neural network only achieves an accuracy of around 38%. With a CNN architecture, you should be able to achieve a higher accuracy of more than 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbuUhbily-Mw"
   },
   "outputs": [],
   "source": [
    "def evaluate(net, testloader):\n",
    "    \n",
    "    # set to evaluation mode\n",
    "    net.eval() \n",
    "\n",
    "    # running_correct\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Repeat for all batch data in the test set\n",
    "    for inputs, targets in testloader:\n",
    "\n",
    "        # transfer to the GPU\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # # disable gradient computation\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # perform inference\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # predict as the best result  \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            running_corrects += (targets == predicted).double().sum()\n",
    "\n",
    "\n",
    "    print('Accuracy = {:.2f}%'.format(100*running_corrects/len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVmtZB_fy-8C"
   },
   "source": [
    "Now, let's evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Q0woXISqAst"
   },
   "outputs": [],
   "source": [
    "evaluate(net, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-oxEglpqAsx"
   },
   "source": [
    "---\n",
    "# 2. CREATING A CNN NETWORK DIRECTLY USING torch.nn.Sequential\n",
    "\n",
    "In this section, we shall learn how to create a network using `torch.nn.Sequential`. `Sequential` is a container of `Modules` that can be stacked together and run at the same time. \n",
    "\n",
    "```\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(....),\n",
    "    nn.ReLU(),\n",
    "    ....\n",
    ")\n",
    "\n",
    "x = ... # get the input tensor\n",
    "output = net(x)  # perform inference\n",
    "```\n",
    "\n",
    "We can see immediately that it is a very convenient way to build a network.\n",
    "\n",
    "*Limitations: Note that you cannot add functional operations (e.g., `torch.relu`) into a `Sequential` model. If the `nn` module version does not exist for the function, then you have to create your own `nn` module for the function.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hntw80gqAs4"
   },
   "source": [
    "**Exercise**. Reimplement the network above using `torch.nn.Sequential`. \n",
    "\n",
    "Since you cannot use functional operations for `Sequential` models, you use their corresponding module versions:\n",
    "* `torch.nn.functional.max_pool2d` --> [`torch.nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)\n",
    "* `torch.nn.functional.relu` --> [`torch.nn.ReLU`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)\n",
    "* `torch.view` --> [`nn.Flatten`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjYESW_IqAs7"
   },
   "outputs": [],
   "source": [
    "net2 = # ... your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDp67m2XJC_m"
   },
   "outputs": [],
   "source": [
    "summary(net2, (3, 32, 32), device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PB-IrMHsqAtC"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kl5_NdRPqAtD"
   },
   "outputs": [],
   "source": [
    "train(net2, trainloader, max_epochs=50, lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlYw_V9SqAtH"
   },
   "source": [
    "### Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJWpnTqnqAtI"
   },
   "outputs": [],
   "source": [
    "evaluate(net2, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV7MzAewqAtO"
   },
   "source": [
    "---\n",
    "# 3. COMBINING torch.nn.Sequential and torch.nn.Module\n",
    "\n",
    "### Build the Network\n",
    "\n",
    "We can embed `nn.Sequential` objects (Section 2) to group layers when defining `nn.Module` definition (Section 1). In the following, we shall group `conv1` and `conv2` into `block_1` and  `conv3` and `conv4` into `block_2`.\n",
    "\n",
    "\n",
    "| Block |Layer | Name | Description | OutputShape |\n",
    "|:---:|:--:|:--|:---:|:---:|\n",
    "|input|-|-|-|(?, 3, 32, 32)|\n",
    "||||||\n",
    "| block_1 | 1 <br><br> - <br><br> 2 <br><br> - | conv1 <br><br> ReLU <br><br> conv2 <br><br> ReLU| Conv2d (k=32,f=3,s=1,p=1)<br><br> relu <br><br> Conv2d (k=32,f=3,s=1,p=1)<br><br> relu| (?, 32, 32, 32) <br><br> (?, 32, 32, 32)<br><br> (?, 32, 32, 32)<br><br> (?, 32, 32, 32) | \n",
    "||||||\n",
    "| - | - | pool1 | maxpool (f=2,s=2,p=0) | (?, 32, 16, 16) | \n",
    "||||||\n",
    "| block_2 | 3 <br><br> - <br><br> 4 <br><br> - | conv1 <br><br> ReLU <br><br> conv2 <br><br> ReLU| Conv2d (k=64,f=3,s=1,p=1)<br><br> relu <br><br> Conv2d (k=64,f=3,s=1,p=1)<br><br> relu| (?, 64, 16, 16) <br><br> (?, 64, 16, 16)<br><br> (?, 64, 16, 16)<br><br> (?, 64, 16, 16) | \n",
    "||||||\n",
    "|  | - | global_pool | AdaptiveAvgPool, o=(1,1) | (?, 64, 1, 1) | \n",
    "|  | - | -           | view                     | (?, 64) | \n",
    "||||||\n",
    "|  | 5 | fc1         | Linear(#units=10)        | (?, 10) | \n",
    "|  | - | -           | view                     | (?, 10) | \n",
    "\n",
    "Notes: `k`: number of filters, `f`: filter or kernel size, `s`: stride, `p`: padding, `o`: output shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JW1HRE9grXZX"
   },
   "source": [
    "To do this, rather than declaring each layer individually, you can declare a  block of multiple layers using `nn.Sequential`:\n",
    "\n",
    "```\n",
    "self.conv_block1 = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XgXW69YqAtO"
   },
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define block 1\n",
    "        self.conv_block1 = # ... your code here ...\n",
    "        \n",
    "        # define block 2\n",
    "        self.conv_block2 = # ... your code here ...\n",
    "\n",
    "        # define global_pool\n",
    "        self.global_pool = # ... your code here ...\n",
    "        \n",
    "        # define fc1\n",
    "        self.fc1 = # ... your code here ...\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # block 1\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # max pool\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # block 2\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # global pool\n",
    "        # ... your code here ...\n",
    "\n",
    "        # view\n",
    "        # ... your code here ...\n",
    "        \n",
    "        # fc1\n",
    "        # ... your code here ...\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqxSyexsgeuJ"
   },
   "outputs": [],
   "source": [
    "net3 = Net3()\n",
    "summary(net3, (3, 32, 32), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj1K9m3PqAtY"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slHmpzWrqAtY"
   },
   "outputs": [],
   "source": [
    "train(net3, trainloader, max_epochs=50, lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJDnBZ2RqAte"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEFIHBp7qAtf"
   },
   "outputs": [],
   "source": [
    "evaluate(net3, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df2XKfZlSM8R"
   },
   "source": [
    "<center>--- End of Practical ---</center>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab05A - Constructing a CNN Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
